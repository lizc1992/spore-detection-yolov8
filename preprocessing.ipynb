{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QgIQy4u72wOa",
        "iXgKQOetHTzh",
        "mUnC0gDfrFqV"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKtg3fv1a2UD",
        "outputId": "351b9376-e4da-4310-e8d2-374ab9cf60d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split each image to four"
      ],
      "metadata": {
        "id": "uNGfyRGV6XT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def split_image_matplotlib(image_path):\n",
        "    img = mpimg.imread(image_path)\n",
        "    basename = os.path.splitext(os.path.basename(image_path))[0]\n",
        "\n",
        "    height, width = img.shape[0], img.shape[1]\n",
        "    print(height, width)\n",
        "    mid_y, mid_x = height // 2, width // 2\n",
        "    print(mid_y, mid_x)\n",
        "    # Define the four quadrants\n",
        "    quadrants = [\n",
        "        img[:mid_y, :mid_x],    # Top-left\n",
        "        img[:mid_y, mid_x:],    # Top-right\n",
        "        img[mid_y:, :mid_x],    # Bottom-left\n",
        "        img[mid_y:, mid_x:],    # Bottom-right\n",
        "    ]\n",
        "\n",
        "    for i, quadrant in enumerate(quadrants, start=1):\n",
        "        save_path = f\"/content/drive/MyDrive/פרוייקט זיהוי נבגים/תמונות של 4 דגימות שונות/split_images/images/{basename}_{i}.png\"\n",
        "        plt.imsave(save_path, quadrant)\n",
        "        print(f\"Saved: {save_path}\")"
      ],
      "metadata": {
        "id": "4-YfMw7pbQ32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "images_to_split = glob.glob('/content/drive/MyDrive/פרוייקט זיהוי נבגים/תמונות של 4 דגימות שונות/new samples/*')\n",
        "for image in images_to_split:\n",
        "  split_image_matplotlib(image)"
      ],
      "metadata": {
        "id": "n5pbvcPwv-3n",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert the initial pickle to json"
      ],
      "metadata": {
        "id": "QgIQy4u72wOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "def pickle_to_json(pickle_file, json_file):\n",
        "    with open(pickle_file, \"rb\") as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    # If it's a numpy array → convert to list\n",
        "    if isinstance(data, np.ndarray):\n",
        "        data = data.tolist()\n",
        "\n",
        "    # If it's something nested (dicts/lists with numpy inside)\n",
        "    def convert(o):\n",
        "        if isinstance(o, np.ndarray):\n",
        "            return o.tolist()\n",
        "        if isinstance(o, (np.int32, np.int64)):\n",
        "            return int(o)\n",
        "        if isinstance(o, (np.float32, np.float64)):\n",
        "            return float(o)\n",
        "        raise TypeError(f\"Object of type {type(o)} is not JSON serializable\")\n",
        "\n",
        "    with open(json_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump({\"points\": data}, f, ensure_ascii=False, indent=4, default=convert)\n"
      ],
      "metadata": {
        "id": "eF65L3gUlf8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import json\n",
        "\n",
        "def plot_image_and_polygon(image_path, json_file, title):\n",
        "    with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    polygons = data[\"points\"]   # list of polygons\n",
        "\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 10))\n",
        "    ax.imshow(img)\n",
        "\n",
        "    for poly in polygons:\n",
        "        points = np.array(poly, dtype=float)\n",
        "        if points.ndim == 2 and points.shape[1] == 2:  # valid [N,2]\n",
        "            ax.plot(points[:, 0], points[:, 1], \"-r\", linewidth=2)\n",
        "            ax.fill(points[:, 0], points[:, 1], alpha=0.3)\n",
        "\n",
        "    ax.set_title(title)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "LuMAvfue41Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove Marks"
      ],
      "metadata": {
        "id": "iXgKQOetHTzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from shapely.geometry import Point, Polygon\n",
        "\n",
        "def filter_polygons(polygons_file, remove_file, output_file_filtered, output_file_dropped):\n",
        "    # Load polygons\n",
        "    with open(polygons_file, \"r\") as f:\n",
        "        poly_data = json.load(f)\n",
        "\n",
        "    # Polygons are stored under key \"points\"\n",
        "    polygons = poly_data[\"points\"]\n",
        "\n",
        "    # Load circle centers\n",
        "    with open(remove_file, \"r\") as f:\n",
        "        circles = json.load(f)\n",
        "    print(f\"There are {len(circles)} marks to remove\")\n",
        "\n",
        "    filtered_polygons = []\n",
        "    dropped_polygons = []\n",
        "    for poly in polygons:\n",
        "        polygon = Polygon(poly)\n",
        "        keep = True\n",
        "        for c in circles:\n",
        "            point = Point(c[\"x\"], c[\"y\"])\n",
        "            if polygon.contains(point):\n",
        "                keep = False\n",
        "                dropped_polygons.append(poly)\n",
        "                break\n",
        "        if keep:\n",
        "            filtered_polygons.append(poly)\n",
        "\n",
        "    # Save filtered polygons\n",
        "    with open(output_file_filtered, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump({\"points\": filtered_polygons}, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "    with open(output_file_dropped, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump({\"points\": dropped_polygons}, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "    print(f\"{len(dropped_polygons)} polygons are dropped.\")\n",
        "    print(f\"Saved files to {output_file_filtered}, {output_file_dropped}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OxlNirqkxJaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add Marks"
      ],
      "metadata": {
        "id": "mUnC0gDfrFqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import math\n",
        "\n",
        "def create_circle_polygon(x, y, radius=5, num_points=20):\n",
        "    \"\"\"Generate a list of [x, y] points approximating a circle.\"\"\"\n",
        "    return [[x + radius * math.cos(2 * math.pi * i / num_points),\n",
        "             y + radius * math.sin(2 * math.pi * i / num_points)]\n",
        "            for i in range(num_points)]\n",
        "\n",
        "def add_circles_to_polygons(polygons_file, add_file, output_file, radius=5, num_points=20):\n",
        "    # Load polygons\n",
        "    with open(polygons_file, \"r\") as f:\n",
        "        poly_data = json.load(f)\n",
        "\n",
        "    polygons = poly_data.get(\"points\", [])\n",
        "\n",
        "    # Load circles to add\n",
        "    with open(add_file, \"r\") as f:\n",
        "        circles = json.load(f)\n",
        "    print(f\"There are {len(circles)} marks to add\")\n",
        "    # Convert each circle into a polygon and append\n",
        "    for c in circles:\n",
        "        circle_poly = create_circle_polygon(c[\"x\"], c[\"y\"], radius=radius, num_points=num_points)\n",
        "        polygons.append(circle_poly)\n",
        "\n",
        "    # Save updated polygons\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump({\"points\": polygons}, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "    print(f\"Saved updated polygons to {output_file}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "V6RPRo49K9Bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full pipeline"
      ],
      "metadata": {
        "id": "48TSCAN_skiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import json\n",
        "import glob\n",
        "pickle_files = glob.glob(\"/content/drive/MyDrive/פרוייקט זיהוי נבגים/תמונות של 4 דגימות שונות/split_images/pickles_new/*.pkl\")\n",
        "for pickle_file in pickle_files:\n",
        "\n",
        "  json_file = pickle_file.replace(\"pickles_new\",\"images\").replace(\".pkl\",\".json\")\n",
        "  image_file = pickle_file.replace(\"pickles_new\",\"images\").replace(\".pkl\",\".png\")\n",
        "  #Convert the polygon to json\n",
        "  pickle_to_json(pickle_file, json_file)\n",
        "  plot_image_and_polygon(image_file, json_file, 'SAM tags')\n",
        "  #Remove marks\n",
        "  marks_to_remove = json_file.replace('/images/','/contour_mask_jsons/').replace('.json', '_contour_mask.json')\n",
        "  filter_polygons(json_file, marks_to_remove, \"/content/filtered_points.json\", \"/content/dropped_points.json\")\n",
        "  plot_image_and_polygon(image_file, \"/content/filtered_points.json\", 'After remove marks')\n",
        "  ###plot_image_and_polygon(image_file,  \"/content/dropped_points.json\", 'Marks were removed')\n",
        "  #Add marks\n",
        "  marks_to_add = json_file.replace('/images/','/background_mask_jsons/').replace('.json', '_background_mask.json')\n",
        "  final_tag = json_file.replace('/images/','/final_tags/')\n",
        "  add_circles_to_polygons(\"/content/filtered_points.json\", marks_to_add, final_tag, radius=20, num_points=40)\n",
        "  plot_image_and_polygon(image_file, final_tag, 'Final tag')\n",
        "\n",
        "  #break"
      ],
      "metadata": {
        "id": "REjqY1JRsmvb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full pipeline after thier tag"
      ],
      "metadata": {
        "id": "RZb0gtxshfj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import json\n",
        "import glob\n",
        "json_files = glob.glob(\"/content/drive/MyDrive/פרוייקט זיהוי נבגים/תמונות של 4 דגימות שונות/split_images/first_manual_tagging/final_tags/*.json\")\n",
        "for json_file in json_files:\n",
        "  file_name = json_file.split('/')[-1].split('.')[0]\n",
        "  image_file = json_file.replace(\"first_manual_tagging/final_tags\",\"images\").replace(\".json\",\".png\")\n",
        "  #Convert the polygon to json\n",
        "  plot_image_and_polygon(image_file, json_file, 'SAM tags')\n",
        "  #Remove marks\n",
        "  marks_to_remove = f\"/content/drive/MyDrive/פרוייקט זיהוי נבגים/JSONs/mark to remove/{file_name}_contour_masked.json\"\n",
        "  filter_polygons(json_file, marks_to_remove, \"/content/filtered_points.json\", \"/content/dropped_points.json\")\n",
        "  plot_image_and_polygon(image_file, \"/content/filtered_points.json\", 'After remove marks')\n",
        "  ###plot_image_and_polygon(image_file,  \"/content/dropped_points.json\", 'Marks were removed')\n",
        "  #Add marks\n",
        "  marks_to_add = f\"/content/drive/MyDrive/פרוייקט זיהוי נבגים/JSONs/mark to add/{file_name}_background_masked.json\"\n",
        "  final_tag = f\"/content/drive/MyDrive/פרוייקט זיהוי נבגים/תמונות של 4 דגימות שונות/split_images/After_Einav_tagging/{file_name}.json\"\n",
        "  add_circles_to_polygons(\"/content/filtered_points.json\", marks_to_add, final_tag, radius=20, num_points=40)\n",
        "  plot_image_and_polygon(image_file, final_tag, 'Final tag')\n",
        "\n",
        "  #break"
      ],
      "metadata": {
        "id": "LUNVSdmOvw_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qOZhzgf0heIP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}